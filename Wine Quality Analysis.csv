REGRESSION,,,,,,,,,,,,,,,,,,,,
Algorithms,MAPE,,,MAE,,,MSE,,,,,,,,,,,,,
,80-20,75-25,70-30,80-20,75-25,70-30,80-20,75-25,70-30,,,,,,,,,,,
Random Forest,7.77%,7.94%,8.72%,0.4306,0.4341,0.4612,33.62%,0.345,0.3958,,,,,,,,,,,
SVM,9.09%,9.12%,8.72%,0.507,0.5042,0.4612,0.4255,0.4269,0.3959,,,,,,,,,,,
Naive Bayes,9.78%,9.51%,11.55%,0.5421,0.5237,0.6279,0.6854,0.6484,0.8358,,,,,,,,,,,
KNN,10.24%,10.41%,11.32%,0.5788,0.582,0.6141,0.5184,0.5222,0.5807,,,,,,,,,,,
Linear Regression,9.25%,9.26%,9.99%,0.5156,0.5109,0.5355,0.5284,0.4262,0.4807,,,,,,,,,,,
Decision Tree,9.56%,9.57%,10.35%,0.5315,0.526,0.5539,0.4389,0.4575,0.5127,,,,,,,,,,,
XG boost,7.60%,7.79%,8.56%,0.4172,0.4269,0.4512,0.3196,0.3952,0.4278,,,,,,,,,,,
Adaboost,9.30%,9.43%,10.51%,0.5235,0.5224,0.5635,0.4299,0.4335,0.4808,,,,,,,,,,,
Gradientboost,8.98%,8.74%,9.41%,0.477,0.4809,0.5023,0.3786,0.3893,0.439,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
CLASSIFICATION,,,,,,,,,,,,,,,,,,,,
Algorithms,Accuracy,,,,,,,,,,,,,,,,,,,
,80-20,75-25,70-30,,,,,,,,,,,,,,,,,
Logistic Regression,70,71,71,,,,,,,,,,,,,,,,,
SVC,72,73,72,,,,,,,,,,,,,,,,,
Decision Tree,66,67,65,,,,,,,,,,,,,,,,,
Naive Bayes,61,61,59,,,,,,,,,,,,,,,,,
KNN,66,67,65,,,,,,,,,,,,,,,,,
Random Forest,79,80,79,,,,,,,,,,,,,,,,,
XG boost,79,78,77,,,,,,,,,,,,,,,,,
Adaboost,74,73,73,,,,,,,,,,,,,,,,,
Gradientboost,75,75,75,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
REGRESSION,REGRESSION,,,,,,,,,CLASSIFICATION,,,,,,,,,,
Neaural Network,NEAURAL NETWORK,,,,,,,,,Neaural Network,,,,,,,,,,
Train and test split,optimizer,Architecture,epochs,learning rate,mse,mae,MAPE,,,Train and test split,optimizer,Architecture,epochs,learning rate,accuracy,,,,,
70-30,adam,64-32-1,10,0.01,0.589,0.6014,11.14%,,,70-30,adam,64-32-1,10,0.01,62,,,,,
70-30,adam,64-32-1,20,0.01,0.5063,0.5433,10.23%,,,70-30,adam,64-32-1,20,0.01,68,,,,,
70-30,adam,64-32-1,40,0.01,1.1709,0.8719,17.07%,,,70-30,adam,64-32-1,40,0.01,70,,,,,
70-30,adam,64-32-1,50,0.01,0.54,0.566,10.16%,,,70-30,adam,64-32-1,50,0.01,73,,,,,
70-30,adam,64-32-1,100,0.01,0.4787,0.53,9.95%,,,70-30,adam,64-32-1,100,0.01,72,,,,,
70-30,adam,64-32-1,500,0.01,0.472,0.5245,9.69%,,,70-30,adam,64-32-1,500,0.01,71,,,,,
70-30,adam,64-32-1,1000,0.01,0.4759,0.5258,9.67%,,,70-30,adam,64-32-1,1000,0.01,74,,,,,
70-30,adam,64-32-1,2000,0.01,0.4878,0.5398,10.15%,,,70-30,adam,64-32-1,2000,0.01,73,,,,,
70-30,adam,64-64-1,100,0.01,0.4757,0.5323,10.05%,,,70-30,adam,64-64-1,100,0.01,73,,,,,
70-30,adam,64-64-1,500,0.01,0.4915,0.5532,10.54%,,,70-30,adam,64-64-1,500,0.01,73,,,,,
70-30,adam,64-64-1,1000,0.01,0.5002,0.5587,10.61%,,,70-30,adam,64-64-1,1000,0.01,72,,,,,
70-30,adam,128-64-32-1,100,0.01,0.6564,0.6413,12.56%,,,70-30,adam,128-64-32-1,100,0.01,68,,,,,
70-30,adam,128-64-32-1,500,0.01,0.6211,0.6135,11.84%,,,70-30,adam,128-64-32-1,500,0.01,72,,,,,
70-30,Adadelta,64-32-1,50,0.01,2.2017,1.1981,21.13%,,,70-30,Adadelta,64-32-1,50,0.01,58,,,,,
70-30,Adadelta,64-32-1,100,0.01,0.6065,0.5872,10.99%,,,70-30,Adadelta,64-32-1,100,0.01,59,,,,,
70-30,Adadelta,64-64-1,500,0.01,0.5255,0.558,10.46%,,,70-30,Adadelta,64-64-1,500,0.01,72,,,,,
70-30,Adadelta,128-64-32-1,1000,0.01,0.516,0.549,10.41%,,,70-30,Adadelta,128-64-32-1,1000,0.01,64,,,,,
70-30,RMSprop,64-32-1,50,0.01,0.6625,0.6529,12.81%,,,70-30,RMSprop,64-32-1,50,0.01,56,,,,,
70-30,RMSprop,64-32-1,100,0.01,0.9322,0.7893,15.53%,,,70-30,RMSprop,64-32-1,100,0.01,66,,,,,
70-30,RMSprop,64-64-1,500,0.01,0.6756,0.6187,10.63%,,,70-30,RMSprop,64-64-1,500,0.01,69,,,,,
70-30,RMSprop,128-64-32-1,1000,0.01,0.7645,0.7007,13.64%,,,70-30,RMSprop,128-64-32-1,1000,0.01,67,,,,,
70-30,Adagrad,64-32-1,50,0.01,1.1085,0.8731,15.23%,,,70-30,Adagrad,64-32-1,50,0.01,72,,,,,
70-30,Adagrad,64-32-1,100,0.01,0.5938,0.6063,11.69%,,,70-30,Adagrad,64-32-1,100,0.01,73,,,,,
70-30,Adagrad,64-64-1,500,0.01,0.4714,0.5266,9.72%,,,70-30,Adagrad,64-64-1,500,0.01,71,,,,,
70-30,Adagrad,128-64-32-1,1000,0.01,0.493,0.5462,10.30%,,,70-30,Adagrad,128-64-32-1,1000,0.01,73,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
Neaural Network,,,,,,,,,,Neaural Network,,,,,,,,,,
Train and test split,optimizer,architecture,epochs,learning rate,mse,mae,MAPE,,,Train and test split,optimizer,Architecture,epochs,learning rate,Accuracy,,,,,
80-20,adam,64-32-1,10,0.01,0.5146,0.5777,10.41%,,,80-20,adam,64-32-1,10,0.01,62,,,,,
80-20,adam,64-32-1,50,0.01,0.4364,0.5164,9.04%,,,80-20,adam,64-32-1,20,0.01,65,,,,,
80-20,adam,64-32-1,100,0.01,0.4656,0.5389,9.84%,,,80-20,adam,64-32-1,40,0.01,71,,,,,
80-20,adam,64-32-1,500,0.01,0.4547,0.5452,9.99%,,,80-20,adam,64-32-1,50,0.01,73,,,,,
80-20,adam,64-32-1,1000,0.01,0.4365,0.5194,9.30%,,,80-20,adam,64-32-1,100,0.01,70,,,,,
80-20,adam,128-64-32-1,50,0.01,0.9418,0.8112,15.48%,,,80-20,adam,64-32-1,500,0.01,72,,,,,
80-20,adam,128-64-32-1,100,0.01,0.446,0.5245,9.08%,,,80-20,adam,64-32-1,1000,0.01,71,,,,,
80-20,adam,128-64-32-1,500,0.01,0.4208,0.5,8.68%,,,80-20,adam,64-32-1,2000,0.01,68,,,,,
80-20,adam,128-64-32-1,1000,0.01,0.423,0.5045,9.01%,,,80-20,adam,64-64-1,100,0.01,73,,,,,
80-20,adam,128-64-32-1,2000,0.01,0.4299,0.5129,9.25%,,,80-20,adam,64-64-1,500,0.01,73.52,,,,,
80-20,adam,64-128-32-1,50,0.01,0.5211,0.5468,9.24%,,,80-20,adam,64-64-1,1000,0.01,73.52,,,,,
80-20,adam,64-128-32-1,100,0.01,0.6565,0.6694,12.65%,,,80-20,adam,64-64-1,2000,0.01,73,,,,,
80-20,adam,64-128-32-1,500,0.01,0.4546,0.5393,9.87%,,,80-20,adam,128-64-32-1,100,0.01,53,,,,,
80-20,adam,64-128-32-1,1000,0.01,0.4761,0.5347,9.67%,,,80-20,adam,128-64-32-1,500,0.01,53,,,,,
80-20,RMSprop,64-128-32-1,50,0.01,0.4451,0.5369,9.75%,,,80-20,SGD,64-64-1,100,0.01,62,,,,,
80-20,RMSprop,64-128-32-1,100,0.01,0.5313,0.5552,9.39%,,,80-20,SGD,64-64-1,500,0.01,68,,,,,
80-20,RMSprop,64-128-32-1,500,0.01,0.5638,0.6017,11.24%,,,80-20,SGD,64-64-1,1000,0.01,66,,,,,
80-20,RMSprop,64-128-32-1,1000,0.01,0.4196,0.5034,9.04%,,,80-20,SGD,64-128-32-1,500,0.01,53,,,,,
80-20,Adadelta,64-32-1,50,0.01,1.4027,0.9539,16.63%,,,80-20,Adadelta,64-32-1,50,0.01,62,,,,,
80-20,Adadelta,64-32-1,100,0.01,0.5198,0.5603,10.07%,,,80-20,Adadelta,64-32-1,100,0.01,61,,,,,
80-20,Adadelta,64-64-1,500,0.01,0.461,0.5245,9.43%,,,80-20,Adadelta,64-64-1,500,0.01,73,,,,,
80-20,Adadelta,128-64-32-1,1000,0.01,0.4383,0.5229,9.54%,,,80-20,Adadelta,128-64-32-1,1000,0.01,73,,,,,
80-20,Adagrad,64-32-1,50,0.01,0.4559,0.5396,9.85%,,,80-20,Adagrad,64-32-1,50,0.01,67,,,,,
80-20,Adagrad,64-32-1,100,0.01,0.8666,0.777,14.75%,,,80-20,Adagrad,64-32-1,100,0.01,66,,,,,
80-20,Adagrad,64-64-1,500,0.01,0.4311,0.5087,9.05%,,,80-20,Adagrad,64-64-1,500,0.01,71,,,,,
80-20,Adagrad,128-64-32-1,1000,0.01,0.4309,0.5137,9.13%,,,80-20,Adagrad,128-64-32-1,1000,0.01,72,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
Neaural Network,,,,,,,,,,,,,,,,,,,,
Train and test split,optimizer,architecture,epochs,learning rate,mse,mae,MAPE,,,Train and test split,optimizer,architecture,epochs,learning rate,accuracy,,,,,
65-35,adam,64-32-1,10,0.01,0.5387,0.5823,11.08%,,,65-35,adam,64-32-1,10,0.01,72,,,,,
65-35,adam,64-32-1,50,0.01,0.4533,0.5198,9.73%,,,65-35,adam,64-32-1,50,0.01,73,,,,,
65-35,adam,64-32-1,100,0.01,0.7072,0.675,11.91%,,,65-35,adam,64-32-1,100,0.01,72,,,,,
65-35,adam,64-32-1,500,0.01,0.4627,0.5351,9.76%,,,65-35,adam,64-32-1,500,0.01,73,,,,,
65-35,adam,64-32-1,1000,0.01,0.4892,0.5249,9.59%,,,65-35,adam,64-32-1,1000,0.01,73,,,,,
65-35,adam,128-64-32-1,50,0.01,0.4621,0.5168,9.55%,,,65-35,adam,128-64-32-1,50,0.01,73,,,,,
65-35,adam,128-64-32-1,100,0.01,0.666,0.6436,11.13%,,,65-35,adam,128-64-32-1,100,0.01,72,,,,,
65-35,adam,128-64-32-1,500,0.01,0.4815,0.5202,9.57%,,,65-35,adam,128-64-32-1,500,0.01,73,,,,,
65-35,adam,128-64-32-1,1000,0.01,0.4623,0.5108,9.29%,,,65-35,adam,128-64-32-1,1000,0.01,72,,,,,
65-35,adam,128-64-32-1,2000,0.01,0.4833,0.5246,9.79%,,,65-35,adam,128-64-32-1,2000,0.01,71,,,,,
65-35,adam,64-128-32-1,50,0.01,0.5336,0.5575,9.82%,,,65-35,adam,64-128-32-1,50,0.01,72,,,,,
65-35,adam,64-128-32-1,100,0.01,0.4998,0.5485,10.47%,,,65-35,adam,64-128-32-1,100,0.01,71,,,,,
65-35,adam,64-128-32-1,500,0.01,0.4759,0.542,10.17%,,,65-35,adam,64-128-32-1,500,0.01,71,,,,,
65-35,adam,64-128-32-1,1000,0.01,0.5104,0.5454,10.41%,,,65-35,adam,64-128-32-1,1000,0.01,72,,,,,
65-35,Adadelta,64-32-1,50,0.01,1.5365,0.9799,16.93%,,,65-35,Adadelta,64-32-1,50,0.01,62,,,,,
65-35,Adadelta,64-32-1,100,0.01,0.6518,0.6312,11.39%,,,65-35,Adadelta,64-32-1,100,0.01,62,,,,,
65-35,Adadelta,64-64-1,500,0.01,0.5229,0.555,10.425,,,65-35,Adadelta,64-64-1,500,0.01,73,,,,,
65-35,Adadelta,128-64-32-1,1000,0.01,0.4779,0.5254,9.81%,,,65-35,Adadelta,128-64-32-1,1000,0.01,67,,,,,
65-35,RMSprop,64-32-1,50,0.01,0.7566,0.7009,13.75%,,,65-35,RMSprop,64-32-1,50,0.01,67,,,,,
65-35,RMSprop,64-32-1,100,0.01,0.5727,0.608,11.76%,,,65-35,RMSprop,64-32-1,100,0.01,70,,,,,
65-35,RMSprop,64-64-1,500,0.01,0.4841,0.5351,9.70%,,,65-35,RMSprop,64-64-1,500,0.01,71,,,,,
65-35,RMSprop,128-64-32-1,1000,0.01,0.4845,0.5392,10.06%,,,65-35,RMSprop,128-64-32-1,1000,0.01,71,,,,,
65-35,Adagrad,64-32-1,50,0.01,0.5007,0.5326,9.75%,,,65-35,Adagrad,64-32-1,50,0.01,67,,,,,
65-35,Adagrad,64-32-1,100,0.01,0.5109,0.543,10.00%,,,65-35,Adagrad,64-32-1,100,0.01,70,,,,,
65-35,Adagrad,64-64-1,500,0.01,0.4891,0.522,9.71%,,,65-35,Adagrad,64-64-1,50,0.01,70,,,,,
65-35,Adagrad,128-64-32-1,1000,0.01,0.4685,0.5188,9.45%,,,65-35,Adagrad,128-64-32-1,50,0.01,75.62,,,,,
,,,,,,,,,,65-35,Adagrad,128-64-32-1,100,0.01,75.44,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
Regression,80-20 Ratio,,,,,,,,,,,,,,,,,,,
Algorithms,MAPE,MAE,MSE,,,,,,,,,,,,,,,,,
Random Forest,7.77%,0.4306,33.62%,,,,,,,,,,,,,,,,,
SVM,9.09%,0.507,0.4255,,,,,,,,,,,,,,,,,
Naive Bayes,9.78%,0.5421,0.6854,,,,,,,,,,,,,,,,,
KNN,10.24%,0.5788,0.5184,,,,,,,,,,,,,,,,,
Linear Regression,9.25%,0.5156,0.5284,,,,,,,,,,,,,,,,,
Decision Tree,9.56%,0.5315,0.4389,,,,,,,,,,,,,,,,,
XG boost,7.60%,0.4172,0.3196,,,,,,,,,,,,,,,,,
Adaboost,9.30%,0.5235,0.4299,,,,,,,,,,,,,,,,,
Gradientboost,8.98%,0.477,0.3786,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
Regression,75-25 Ratio,,,,,,,,,,,,,,,,,,,
Algorithms,MAPE,MAE,MSE,,,,,,,,,,,,,,,,,
Random Forest,7.94%,0.4341,0.345,,,,,,,,,,,,,,,,,
SVM,9.12%,0.5042,0.4269,,,,,,,,,,,,,,,,,
Naive Bayes,9.51%,0.5237,0.6484,,,,,,,,,,,,,,,,,
KNN,10.41%,0.582,0.5222,,,,,,,,,,,,,,,,,
Linear Regression,9.26%,0.5109,0.4262,,,,,,,,,,,,,,,,,
Decision Tree,9.57%,0.526,0.4575,,,,,,,,,,,,,,,,,
XG boost,7.79%,0.4269,0.3952,,,,,,,,,,,,,,,,,
Adaboost,9.43%,0.5224,0.4335,,,,,,,,,,,,,,,,,
Gradientboost,8.74%,0.4809,0.3893,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
Regression,70-30 Ratio,,,,,,,,,,,,,,,,,,,
Algorithms,MAPE,MAE,MSE,,,,,,,,,,,,,,,,,
Random Forest,8.72%,0.4612,0.3958,,,,,,,,,,,,,,,,,
SVM,8.72%,0.4612,0.3959,,,,,,,,,,,,,,,,,
Naive Bayes,11.55%,0.6279,0.8358,,,,,,,,,,,,,,,,,
KNN,11.32%,0.6141,0.5807,,,,,,,,,,,,,,,,,
Linear Regression,9.99%,0.5355,0.4807,,,,,,,,,,,,,,,,,
Decision Tree,10.35%,0.5539,0.5127,,,,,,,,,,,,,,,,,
XG boost,8.56%,0.4512,0.4278,,,,,,,,,,,,,,,,,
Adaboost,10.51%,0.5635,0.4808,,,,,,,,,,,,,,,,,
Gradientboost,9.41%,0.5023,0.439,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
Classification,,,,,,,,,,,,,,,,,,,,
Algorithms,Accuracy,,,,,,,,,,,,,,,,,,,
Logistic Regression,70,,,,,,,,,,,https://colab.research.google.com/drive/1zIVkjy8TKoKHWBUNdfvcKsZ0Q6Iwpavm?usp=sharing,,,,,,,,
SVC,72,,,,,,,,,,,,,,,,,,,
Decision Tree,66,,,,,,,,,,,,,,,,,,,
Naive Bayes,61,,,,,,,,,,,,,,,,,,,
KNN,66,,,,,,,,,,,,,,,,,,,
Random Forest,79,,,,,,,,,,,,,,,,,,,
XG boost,79,,,,,,,,,,,,,,,,,,,
Adaboost,74,,,,,,,,,,,,,,,,,,,
Gradientboost,75,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
Classification,,,,,,,,,,,,,,,,,,,,
Algorithms,Accuracy,,,,,,,,,,,,,,,,,,,
Logistic Regression,71,,,,,,,,,,,,,,,,,,,
SVC,73,,,,,,,,,,,,,,,,,,,
Decision Tree,67,,,,,,,,,,,,,,,,,,,
Naive Bayes,61,,,,,,,,,,,,,,,,,,,
KNN,67,,,,,,,,,,,,,,,,,,,
Random Forest,80,,,,,,,,,,,,,,,,,,,
XG boost,78,,,,,,,,,,,,,,,,,,,
Adaboost,73,,,,,,,,,,,,,,,,,,,
Gradientboost,75,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,
Classification,,,,,,,,,,,,,,,,,,,,
Algorithms,Accuracy,,,,,,,,,,,,,,,,,,,
Logistic Regression,71,,,,,,,,,,,,,,,,,,,
SVC,72,,,,,,,,,,,,,,,,,,,
Decision Tree,65,,,,,,,,,,,,,,,,,,,
Naive Bayes,59,,,,,,,,,,,,,,,,,,,
KNN,65,,,,,,,,,,,,,,,,,,,
Random Forest,79,,,,,,,,,,,,,,,,,,,
XG boost,77,,,,,,,,,,,,,,,,,,,
Adaboost,73,,,,,,,,,,,,,,,,,,,
Gradientboost,75,,,,,,,,,,,,,,,,,,,
